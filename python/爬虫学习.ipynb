{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "爬虫学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 爬虫的工具列表大全\n",
    "这个列表包含与网页抓取和数据处理的 Python 库。\n",
    "\n",
    "网络\n",
    "通用\n",
    "urllib - 网络库 (stdlib)。\n",
    "requests - 网络库。\n",
    "grab – 网络库（基于 pycurl）。\n",
    "pycurl – 网络库（绑定 libcurl）。\n",
    "urllib3 – Python HTTP 库，安全连接池、支持文件 post、可用性高。\n",
    "httplib2 – 网络库。\n",
    "RoboBrowser – 一个简单的、极具 Python 风格的 Python 库，无需独立的浏览器即可浏览网页。\n",
    "MechanicalSoup - 一个与网站自动交互 Python 库。\n",
    "mechanize - 有状态、可编程的 Web 浏览库。\n",
    "socket – 底层网络接口 (stdlib)。\n",
    "Unirest for Python – Unirest 是一套可用于多种语言的轻量级的 HTTP 库。\n",
    "hyper – Python 的 HTTP/2 客户端。\n",
    "PySocks – SocksiPy 更新并积极维护的版本，包括错误修复和一些其他的特征。作为 socket 模块的直接替换。\n",
    "异步\n",
    "treq – 类似于 requests 的 API（基于 twisted）。\n",
    "aiohttp – asyncio 的 HTTP 客户端 / 服务器 (PEP-3156)。\n",
    "网络爬虫框架\n",
    "功能齐全的爬虫\n",
    "grab – 网络爬虫框架（基于 pycurl/multicur）。\n",
    "scrapy – 网络爬虫框架（基于 twisted）\n",
    "pyspider – 一个强大的爬虫系统。\n",
    "cola – 一个分布式爬虫框架。\n",
    "其他\n",
    "portia – 基于 Scrapy 的可视化爬虫。\n",
    "restkit – Python 的 HTTP 资源工具包。它可以让你轻松地访问 HTTP 资源，并围绕它建立的对象。\n",
    "demiurge – 基于 PyQuery 的爬虫微框架。\n",
    "HTML/XML 解析器\n",
    "通用\n",
    "lxml – C 语言编写高效 HTML/ XML 处理库。支持 XPath。\n",
    "cssselect – 解析 DOM 树和 CSS 选择器。\n",
    "pyquery – 解析 DOM 树和 jQuery 选择器。\n",
    "BeautifulSoup – 低效 HTML/ XML 处理库，纯 Python 实现。\n",
    "html5lib – 根据 WHATWG 规范生成 HTML/ XML 文档的 DOM。该规范被用在现在所有的浏览器上。\n",
    "feedparser – 解析 RSS/ATOM feeds。\n",
    "MarkupSafe – 为 XML/HTML/XHTML 提供了安全转义的字符串。\n",
    "xmltodict – 一个可以让你在处理 XML 时感觉像在处理 JSON 一样的 Python 模块。\n",
    "xhtml2pdf – 将 HTML/CSS 转换为 PDF。\n",
    "untangle – 轻松实现将 XML 文件转换为 Python 对象。\n",
    "清理\n",
    "Bleach – 清理 HTML（需要 html5lib）。\n",
    "sanitize – 为混乱的数据世界带来清明。\n",
    "文本处理\n",
    "用于解析和操作简单文本的库。\n",
    "\n",
    "通用\n",
    "difflib – （Python 标准库）帮助进行差异化比较。\n",
    "Levenshtein – 快速计算 Levenshtein 距离和字符串相似度。\n",
    "fuzzywuzzy – 模糊字符串匹配。\n",
    "esmre – 正则表达式加速器。\n",
    "ftfy – 自动整理 Unicode 文本，减少碎片化。\n",
    "转换\n",
    "unidecode – 将 Unicode 文本转为 ASCII。\n",
    "字符编码\n",
    "uniout – 打印可读字符，而不是被转义的字符串。\n",
    "chardet – 兼容 Python 的 2/3 的字符编码器。\n",
    "xpinyin – 一个将中国汉字转为拼音的库。\n",
    "pangu.py – 格式化文本中 CJK 和字母数字的间距。\n",
    "Slug 化\n",
    "awesome-slugify – 一个可以保留 unicode 的 Python slugify 库。\n",
    "python-slugify – 一个可以将 Unicode 转为 ASCII 的 Python slugify 库。\n",
    "unicode-slugify – 一个可以将生成 Unicode slugs 的工具。\n",
    "pytils – 处理俄语字符串的简单工具（包括 pytils.translit.slugify）。\n",
    "通用解析器\n",
    "PLY – lex 和 yacc 解析工具的 Python 实现。\n",
    "pyparsing – 一个通用框架的生成语法分析器。\n",
    "人的名字\n",
    "python-nameparser - 解析人的名字的组件。\n",
    "电话号码\n",
    "phonenumbers - 解析，格式化，存储和验证国际电话号码。\n",
    "用户代理字符串\n",
    "python-user-agents – 浏览器用户代理的解析器。\n",
    "HTTP Agent Parser – Python 的 HTTP 代理分析器。\n",
    "特定格式文件处理\n",
    "解析和处理特定文本格式的库。\n",
    "\n",
    "通用\n",
    "tablib – 一个把数据导出为 XLS、CSV、JSON、YAML 等格式的模块。\n",
    "textract – 从各种文件中提取文本，比如 Word、PowerPoint、PDF 等。\n",
    "messytables – 解析混乱的表格数据的工具。\n",
    "rows – 一个常用数据接口，支持的格式很多（目前支持 CSV，HTML，XLS，TXT – 将来还会提供更多！）。\n",
    "Office\n",
    "python-docx – 读取，查询和修改的 Microsoft Word2007/2008 的 docx 文件。\n",
    "xlwt /xlrd – 从 Excel 文件读取写入数据和格式信息。\n",
    "XlsxWriter – 一个创建 Excel.xlsx 文件的 Python 模块。\n",
    "xlwings – 一个 BSD 许可的库，可以很容易地在 Excel 中调用 Python，反之亦然。\n",
    "openpyxl – 一个用于读取和写入的 Excel2010 XLSX/ XLSM/xltx/ XLTM 文件的库。\n",
    "Marmir – 提取 Python 数据结构并将其转换为电子表格。\n",
    "PDF\n",
    "PDFMiner – 一个从 PDF 文档中提取信息的工具。\n",
    "PyPDF2 – 一个能够分割、合并和转换 PDF 页面的库。\n",
    "ReportLab – 允许快速创建丰富的 PDF 文档。\n",
    "pdftables – 直接从 PDF 文件中提取表格。\n",
    "Markdown\n",
    "Python-Markdown – 一个用 Python 实现的 John Gruber 的 Markdown。\n",
    "Mistune – 速度最快，功能全面的 Markdown 纯 Python 解析器。\n",
    "markdown2 – 一个完全用 Python 实现的快速的 Markdown。\n",
    "YAML\n",
    "PyYAML – 一个 Python 的 YAML 解析器。\n",
    "CSS\n",
    "cssutils – 一个 Python 的 CSS 库。\n",
    "ATOM/RSS\n",
    "feedparser – 通用的 feed 解析器。\n",
    "SQL\n",
    "sqlparse – 一个非验证的 SQL 语句分析器。\n",
    "HTTP\n",
    "http-parser – C 语言实现的 HTTP 请求 / 响应消息解析器。\n",
    "微格式\n",
    "opengraph – 一个用来解析 Open Graph 协议标签的 Python 模块。\n",
    "可移植的执行体\n",
    "pefile – 一个多平台的用于解析和处理可移植执行体（即 PE）文件的模块。\n",
    "PSD\n",
    "psd-tools – 将 Adobe Photoshop PSD（即 PE）文件读取到 Python 数据结构。\n",
    "自然语言处理\n",
    "处理人类语言问题的库。\n",
    "\n",
    "NLTK - 编写 Python 程序来处理人类语言数据的最好平台。\n",
    "Pattern – Python 的网络挖掘模块。他有自然语言处理工具，机器学习以及其它。\n",
    "TextBlob – 为深入自然语言处理任务提供了一致的 API。是基于 NLTK 以及 Pattern 的巨人之肩上发展的。\n",
    "jieba – 中文分词工具。\n",
    "SnowNLP – 中文文本处理库。\n",
    "loso – 另一个中文分词库。\n",
    "genius – 基于条件随机域的中文分词。\n",
    "langid.py – 独立的语言识别系统。\n",
    "Korean – 一个韩文形态库。\n",
    "pymorphy2 – 俄语形态分析器（词性标注 + 词形变化引擎）。\n",
    "PyPLN  – 用 Python 编写的分布式自然语言处理通道。这个项目的目标是创建一种简单的方法使用 NLTK 通过网络接口处理大语言库。\n",
    "浏览器自动化与仿真\n",
    "selenium – 自动化真正的浏览器（Chrome 浏览器，火狐浏览器，Opera 浏览器，IE 浏览器）。\n",
    "Ghost.py – 对 PyQt 的 webkit 的封装（需要 PyQT）。\n",
    "Spynner – 对 PyQt 的 webkit 的封装（需要 PyQT）。\n",
    "Splinter – 通用 API 浏览器模拟器（selenium web 驱动，Django 客户端，Zope）。\n",
    "多重处理\n",
    "threading – Python 标准库的线程运行。对于 I/O 密集型任务很有效。对于 CPU 绑定的任务没用，因为 python GIL。\n",
    "multiprocessing – 标准的 Python 库运行多进程。\n",
    "celery – 基于分布式消息传递的异步任务队列 / 作业队列。\n",
    "concurrent-futures – concurrent-futures 模块为调用异步执行提供了一个高层次的接口。\n",
    "异步\n",
    "异步网络编程库\n",
    "\n",
    "asyncio – （在 Python 3.4 + 版本以上的 Python 标准库）异步 I/O，时间循环，协同程序和任务。\n",
    "Twisted – 基于事件驱动的网络引擎框架。\n",
    "Tornado – 一个网络框架和异步网络库。\n",
    "pulsar – Python 事件驱动的并发框架。\n",
    "diesel – Python 的基于绿色事件的 I/O 框架。\n",
    "gevent – 一个使用 greenlet 的基于协程的 Python 网络库。\n",
    "eventlet – 有 WSGI 支持的异步框架。\n",
    "Tomorrow – 异步代码的奇妙的修饰语法。\n",
    "队列\n",
    "celery – 基于分布式消息传递的异步任务队列 / 作业队列。\n",
    "huey – 小型多线程任务队列。\n",
    "mrq – Mr. Queue – 使用 redis & Gevent 的 Python 分布式工作任务队列。\n",
    "RQ – 基于 Redis 的轻量级任务队列管理器。\n",
    "simpleq – 一个简单的，可无限扩展，基于 Amazon SQS 的队列。\n",
    "python-gearman – Gearman 的 Python API。\n",
    "云计算\n",
    "picloud – 云端执行 Python 代码。\n",
    "dominoup.com – 云端执行 R，Python 和 matlab 代码。\n",
    "电子邮件\n",
    "电子邮件解析库\n",
    "\n",
    "flanker – 电子邮件地址和 Mime 解析库。\n",
    "Talon – Mailgun 库用于提取消息的报价和签名。\n",
    "网址和网络地址操作\n",
    "解析 / 修改网址和网络地址库。\n",
    "\n",
    "URL\n",
    "furl – 一个小的 Python 库，使得操纵 URL 简单化。\n",
    "purl – 一个简单的不可改变的 URL 以及一个干净的用于调试和操作的 API。\n",
    "urllib.parse – 用于打破统一资源定位器（URL）的字符串在组件（寻址方案，网络位置，路径等）之间的隔断，为了结合组件到一个 URL 字符串，并将 “相对 URL” 转化为一个绝对 URL，称之为 “基本 URL”。\n",
    "tldextract – 从 URL 的注册域和子域中准确分离 TLD，使用公共后缀列表。\n",
    "网络地址\n",
    "netaddr – 用于显示和操纵网络地址的 Python 库。\n",
    "网页内容提取\n",
    "提取网页内容的库。\n",
    "\n",
    "HTML 页面的文本和元数据\n",
    "newspaper – 用 Python 进行新闻提取、文章提取和内容策展。\n",
    "html2text – 将 HTML 转为 Markdown 格式文本。\n",
    "python-goose – HTML 内容 / 文章提取器。\n",
    "lassie – 人性化的网页内容检索工具\n",
    "micawber – 一个从网址中提取丰富内容的小库。\n",
    "sumy - 一个自动汇总文本文件和 HTML 网页的模块\n",
    "Haul – 一个可扩展的图像爬虫。\n",
    "python-readability – arc90 readability 工具的快速 Python 接口。\n",
    "scrapely – 从 HTML 网页中提取结构化数据的库。给出了一些 Web 页面和数据提取的示例，scrapely 为所有类似的网页构建一个分析器。\n",
    "视频\n",
    "youtube-dl – 一个从 YouTube 下载视频的小命令行程序。\n",
    "you-get – Python3 的 YouTube、优酷 / Niconico 视频下载器。\n",
    "维基\n",
    "WikiTeam – 下载和保存 wikis 的工具。\n",
    "WebSocket\n",
    "用于 WebSocket 的库。\n",
    "\n",
    "Crossbar – 开源的应用消息传递路由器（Python 实现的用于 Autobahn 的 WebSocket 和 WAMP）。\n",
    "AutobahnPython – 提供了 WebSocket 协议和 WAMP 协议的 Python 实现并且开源。\n",
    "WebSocket-for-Python – Python 2 和 3 以及 PyPy 的 WebSocket 客户端和服务器库。\n",
    "DNS 解析\n",
    "dnsyo – 在全球超过 1500 个的 DNS 服务器上检查你的 DNS。\n",
    "pycares – c-ares 的接口。c-ares 是进行 DNS 请求和异步名称决议的 C 语言库。\n",
    "计算机视觉\n",
    "OpenCV – 开源计算机视觉库。\n",
    "SimpleCV – 用于照相机、图像处理、特征提取、格式转换的简介，可读性强的接口（基于 OpenCV）。\n",
    "mahotas – 快速计算机图像处理算法（完全使用 C++ 实现），完全基于 numpy 的数组作为它的数据类型。\n",
    "代理服务器\n",
    "Shadowsocks – 一个快速隧道代理，可帮你穿透防火墙（支持 TCP 和 UDP，TFO，多用户和平滑重启，目的 IP 黑名单）。\n",
    "tproxy – tproxy 是一个简单的 TCP 路由代理（第 7 层），基于 Gevent，用 Python 进行配置。\n",
    "其他 Python 工具列表\n",
    "awesome-python\n",
    "pycrumbs\n",
    "python-github-projects\n",
    "python_reference\n",
    "pythonidae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XPath 语法\n",
    "https://qq52o.me/2203.html\n",
    "\n",
    "Python爬虫常用的小技巧-设置代理IP\n",
    "https://qq52o.me/2284.html\n",
    "\n",
    "Python爬虫常用的小技巧-伪造随机的User-Agent\n",
    "https://qq52o.me/2281.html\n",
    "ua的方法\n",
    "https://github.com/sy-records/speech_spiders/blob/master/nihaowu/nihaowua-v2.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 使用 fake-useragent 库时报错的解决方法\n",
    "https://qq52o.me/2505.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
